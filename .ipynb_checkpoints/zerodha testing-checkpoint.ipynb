{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf6bb8da-5be9-494c-aa72-bced94edec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import pytz\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from kiteconnect import KiteConnect\n",
    "from selenium import webdriver\n",
    "import urllib.parse as urlparse\n",
    "from selenium.webdriver.common.by import By\n",
    "import time, pyotp\n",
    "from nsepython import nse_holidays, nsefetch\n",
    "from datetime import datetime, timedelta\n",
    "from stocklist import symbols\n",
    "import sys\n",
    "\n",
    "# configure logging once at the start of your script\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "zerodha_key = \"vs36q6a3dlmzw3ot\"\n",
    "zerodha_secret = \"n0zui30yjyc8khw1guoxfe6ci25g2ap2\"\n",
    "zerodha_user = \"ZO2506\"\n",
    "zerodha_password = \"Apitest#000\"\n",
    "zerodha_totp_secret = \"GYVOVCJ5IMYGGA44HHBPL6ZI4JULUXKZ\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b90a27b6-9dcb-4c8a-ba9e-84502bb5706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 22:04:16,532 - INFO - Initializing Chrome WebDriver...\n",
      "2025-09-28 22:04:16,543 - INFO - ====== WebDriver manager ======\n",
      "2025-09-28 22:04:21,087 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-09-28 22:04:21,319 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-09-28 22:04:21,370 - INFO - Driver [C:\\Users\\chand\\.wdm\\drivers\\chromedriver\\win64\\140.0.7339.207\\chromedriver-win32/chromedriver.exe] found in cache\n",
      "2025-09-28 22:04:26,212 - INFO - ✅ WebDriver initialized successfully!\n",
      "2025-09-28 22:04:26,214 - INFO - https://kite.zerodha.com/connect/login?api_key=vs36q6a3dlmzw3ot&v=3\n",
      "2025-09-28 22:04:28,734 - INFO - ✅ Login successful.. going to sleep for 3 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OTP generated : 356244\n",
      "OTP Validated.. going to sleep for 2 secs\n",
      "Request Token: W0V9SRzwFxWrMkTTztSG1ZmpUYWEmRQC\n",
      "Access Token: JFAq9gj0X81r708HV5v0bXtce1DE0VwD\n",
      "Logged in as: Nirav Kirti Shah\n"
     ]
    }
   ],
   "source": [
    "kite = KiteConnect(api_key=zerodha_key)\n",
    "\n",
    "# 1. Open login URL in Selenium\n",
    "# Auto-download and use correct ChromeDriver version\n",
    "# Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # comment this if you want to see browser\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "try:\n",
    "    # Start Selenium with webdriver-manager\n",
    "    logging.info(\"Initializing Chrome WebDriver...\")\n",
    "    \n",
    "    try:\n",
    "        # Install and setup ChromeDriver\n",
    "        # Start Selenium with webdriver-manager\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),\n",
    "                          options=chrome_options)\n",
    "        logging.info(\"✅ WebDriver initialized successfully!\")\n",
    "        \n",
    "    except SessionNotCreatedException as e:\n",
    "        logging.error(f\"❌ Error: Chrome version compatibility issue - {e}\")\n",
    "        logging.error(\"❌ This might be due to browser-driver version mismatch.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    except WebDriverException as e:\n",
    "        logging.error(f\"❌ Error: WebDriver initialization failed - {e}\")\n",
    "        logging.error(\"❌ Please check if Chrome is installed and updated.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"❌ Unexpected error during WebDriver setup: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Print login URL with exception handling\n",
    "    try:\n",
    "        logging.info(kite.login_url())\n",
    "        driver.get(kite.login_url())\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        \n",
    "        # 2. Enter user_id + password\n",
    "        wait.until(EC.presence_of_element_located((By.ID, \"userid\"))).send_keys(zerodha_user)\n",
    "        driver.find_element(By.ID, \"password\").send_keys(zerodha_password)\n",
    "        driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
    "        logging.info(\"✅ Login successful.. going to sleep for 3 secs\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "    except NameError:\n",
    "        logging.error(\"❌ Error: 'kite' object not found or not initialized\")\n",
    "        logging.error(\"❌ Please ensure the kite object is properly created\")\n",
    "        \n",
    "    except AttributeError:\n",
    "        logging.error(\"❌ Error: 'login_url' method not found in kite object\")\n",
    "        logging.error(\"❌ Please check if the method name is correct\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error retrieving login URL: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "except NameError:\n",
    "    logging.error(\"❌ Error: 'chrome_options' not defined\")\n",
    "    logging.error(\"❌ Please define chrome_options before initializing WebDriver\")\n",
    "    sys.exit(1)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"❌ Unexpected error in main execution: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 3. Enter TOTP\n",
    "totp = pyotp.TOTP(zerodha_totp_secret).now()\n",
    "print(\"OTP generated :\", totp)\n",
    "# wait.until(EC.presence_of_element_located((By.ID, \"totp\"))).send_keys(totp)\n",
    "# driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[2]/div[1]/div/div/div[2]/form/div[2]/div/input\").send_keys(totp)\n",
    "driver.find_element(By.ID, \"userid\").send_keys(totp)\n",
    "driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
    "\n",
    "print(\"OTP Validated.. going to sleep for 2 secs\")\n",
    "time.sleep(2)\n",
    "\n",
    "# 4. Extract request_token from redirected URL\n",
    "current_url = driver.current_url\n",
    "driver.quit()\n",
    "\n",
    "# URL looks like: https://your-redirect-url/?status=success&request_token=xxxx\n",
    "parsed = urlparse.urlparse(current_url)\n",
    "request_token = urlparse.parse_qs(parsed.query)[\"request_token\"][0]\n",
    "print(\"Request Token:\", request_token)\n",
    "\n",
    "# 5. Exchange request_token for access_token\n",
    "data = kite.generate_session(request_token, api_secret=zerodha_secret)\n",
    "access_token = data[\"access_token\"]\n",
    "kite.set_access_token(access_token)\n",
    "print(\"Access Token:\", access_token)\n",
    "\n",
    "# Example API call\n",
    "profile = kite.profile()\n",
    "print(\"Logged in as:\", profile[\"user_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a516a546-04e7-4e2e-8666-6be960e26fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\"\"\"\"\"\"\"\"\" Check if given date is trading holiday \"\"\"\"\"\"\"\"\"\"\"\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "def holiday_check(date):\n",
    "    # Step 1 : Get list of trading holidays with description\n",
    "    try:\n",
    "        df_holidays = pd.json_normalize(nse_holidays()['FO'])\n",
    "    except Exception as e:\n",
    "        print(\"An unexpected error occurred while fetching holidays from NSE:\", e)\n",
    "        print(\"Skipping holiday check now\", e)\n",
    "        return False\n",
    "    # print(df_holidays.head(50))\n",
    "\n",
    "    # Step 2 : Convert into dataframe\n",
    "    df_holidays['tradingDate'] = pd.to_datetime(df_holidays['tradingDate'])\n",
    "\n",
    "    # Step 3: Date to check\n",
    "    check_date = pd.to_datetime(date)  # Example: Gandhi Jayanti\n",
    "\n",
    "    # Step 4: Check if the date is a holiday\n",
    "    if check_date in df_holidays['tradingDate'].values:\n",
    "        logging.info(f\"{check_date.date()} is a holiday: {df_holidays[df_holidays['tradingDate'] == check_date]['description'].values[0]}\")       \n",
    "        return True\n",
    "    else:\n",
    "        logging.info(f\"{check_date.date()} is NOT a holiday.\")\n",
    "        # print(f\"{check_date.date()} is NOT a holiday.\")\n",
    "        return False\n",
    "\n",
    "# prev_week_num - number of week to go back\n",
    "# offset : 0 - Monday,  1 - Tuesday,  ....., 4 - Friday\n",
    "def get_nth_working_day(prev_week_num, offset):\n",
    "    # Today's date\n",
    "    tz = pytz.timezone('Asia/Kolkata')\n",
    "    today = datetime.today().now(tz)\n",
    "    # today = datetime.today()\n",
    "    # print(today.tzinfo is not None)\n",
    "\n",
    "    # Weekday: Monday = 0 ... Sunday = 6\n",
    "    days_since_offset = (today.weekday() - offset) % 7\n",
    "\n",
    "    # Go back to last working day, then back by (n-1)*7 days\n",
    "    total_days_back = days_since_offset + (prev_week_num - 1) * 7\n",
    "\n",
    "    # Last Target day\n",
    "    target_day = today - timedelta(days=total_days_back)\n",
    "    return target_day.date()\n",
    "\n",
    "    \n",
    "# working days of week calculation\n",
    "def get_working_days():\n",
    "    # if today is Monday then give 2 for prev_monday else 3 and so on    \n",
    "    logging.info(f\"Today is : {datetime.today().weekday()}\")\n",
    "    \n",
    "    if datetime.today().weekday() == 0 or datetime.today().weekday() == 6:\n",
    "        prev_monday = get_nth_working_day(2, 0)\n",
    "        last_monday = get_nth_working_day(1, 0)\n",
    "    else:\n",
    "        prev_monday = get_nth_working_day(2, 0)\n",
    "        last_monday = get_nth_working_day(1, 0)\n",
    "\n",
    "    if datetime.today().weekday() == 4:\n",
    "        prev_friday = get_nth_working_day(3, 4)\n",
    "        last_friday = get_nth_working_day(2, 4)\n",
    "    else:\n",
    "        prev_friday = get_nth_working_day(2, 4)\n",
    "        last_friday = get_nth_working_day(1, 4)\n",
    "    \n",
    "    logging.info(f\"Before holiday check --> {prev_monday}, {prev_friday}, {last_monday}, {last_friday}\")\n",
    "\n",
    "    first_week_open_date = prev_monday\n",
    "    while (holiday_check(first_week_open_date)):\n",
    "        first_week_open_date = first_week_open_date + timedelta(days=1)\n",
    "\n",
    "    last_week_open_date = last_monday\n",
    "    while (holiday_check(last_week_open_date)):\n",
    "        last_week_open_date = last_week_open_date + timedelta(days=1)\n",
    "\n",
    "    first_week_close_date = prev_friday\n",
    "    while (holiday_check(first_week_close_date)):\n",
    "        first_week_close_date = first_week_close_date - timedelta(days=1)\n",
    "\n",
    "    last_week_close_date = last_friday\n",
    "    while (holiday_check(last_week_close_date)):\n",
    "        last_week_close_date = last_week_close_date - timedelta(days=1)\n",
    "\n",
    "    logging.info(f\"After holiday check --> {first_week_open_date}, {first_week_close_date}, {last_week_open_date}, {last_week_close_date}\")\n",
    "    \n",
    "    return first_week_open_date, first_week_close_date, last_week_open_date, last_week_close_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf988fe3-eff3-4283-99c1-684627a7731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = kite.instruments(\"NFO\")  # NSE Futures & Options\n",
    "instruments_df = pd.DataFrame(instruments)\n",
    "if not instruments_df.empty: \n",
    "   # Save to CSV\n",
    "   formatted = datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\n",
    "   csv_filename = f\"zerodha_NFO_original_{formatted}.csv\"\n",
    "   instruments_df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a5554a9-99a4-4b39-93b1-7f1f86e4543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ltp(symbol: str, exchange: str = \"NSE\"):\n",
    "    \"\"\"\n",
    "    Get the last traded price for a given symbol.\n",
    "    Example: get_ltp(\"TCS\"), get_ltp(\"RELIANCE\"), get_ltp(\"NIFTY 50\", \"NSE\")\n",
    "    \"\"\"\n",
    "    instrument_token = f\"{exchange}:{symbol}\"\n",
    "    # print(instrument_token)\n",
    "    data = kite.ltp([instrument_token])\n",
    "    return data[instrument_token][\"last_price\"]\n",
    "    \n",
    "# instrument_token = \"NSE:ABB\"\n",
    "# data = kite.ltp([instrument_token])\n",
    "# data[instrument_token][\"last_price\"]\n",
    "\n",
    "# instruments_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a9cd6cb-6af4-46f2-ad21-e6826d139b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expiry_date(instruments_df):\n",
    "      \n",
    "    # Match records where `name` or `tradingsymbol` contains the symbol\n",
    "    matched_df = instruments_df[(instruments_df[\"name\"] == \"ABB\")]\n",
    "\n",
    "    matched_df.head(5)\n",
    "    # Ensure expiry is datetime type\n",
    "    symbol_df = pd.DataFrame()\n",
    "    symbol_df[\"expiry\"] = pd.to_datetime(matched_df[\"expiry\"])\n",
    "    \n",
    "    # Get unique sorted expiries\n",
    "    expiries = sorted(symbol_df[\"expiry\"].unique())\n",
    "   \n",
    "    if not expiries:\n",
    "        return None  # ✅ No expiries available\n",
    "\n",
    "    # Pick the nearest expiry first\n",
    "    selected_expiry = expiries[0]\n",
    "\n",
    "    # ✅ Convert today's date to Timestamp\n",
    "    today = pd.Timestamp(datetime.today().date())\n",
    "    \n",
    "    # ✅ If nearest expiry is within 5 days, move to next one (if available)\n",
    "    if (selected_expiry - today).days < 5 and len(expiries) > 1:\n",
    "        selected_expiry = expiries[1]\n",
    "\n",
    "    logging.info(f\"selected_expiry : {selected_expiry.date()}\")\n",
    "    \n",
    "    return selected_expiry.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c4096d3-69e6-4fa7-a81c-7e7f66c4e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_option_strikes(df, symbol: str, min_strike: float, option_type: str = \"CE\", expiry: str = None):\n",
    "    \"\"\"\n",
    "    Filter option contracts for a given symbol with strike above min_strike.\n",
    "    Allows filtering CALL (CE) or PUT (PE).\n",
    "    If expiry is not provided, the nearest expiry will be used.\n",
    "\n",
    "    Args:\n",
    "        symbol (str): Underlying symbol (e.g., \"TCS\")\n",
    "        min_strike (float): Minimum strike price threshold\n",
    "        option_type (str): \"CE\" for Call, \"PE\" for Put (default = \"CE\")\n",
    "        expiry (str, optional): Expiry date in format \"YYYY-MM-DD\". Defaults to nearest expiry.\n",
    "    \"\"\"\n",
    "    # Validate option type\n",
    "    if option_type not in [\"CE\", \"PE\"]:\n",
    "        raise ValueError(\"option_type must be 'CE' or 'PE'\")\n",
    "\n",
    "    # print(df[df[\"expiry\"]])\n",
    "    if (option_type == \"CE\"):\n",
    "        symbol_df = df[(df[\"name\"] == symbol) & \n",
    "                   (df[\"strike\"] > min_strike) & \n",
    "                   (df[\"instrument_type\"] == option_type) &\n",
    "                   (df[\"expiry\"] == expiry)]\n",
    "    else:\n",
    "        symbol_df = df[(df[\"name\"] == symbol) & \n",
    "                   (df[\"strike\"] < min_strike) & \n",
    "                   (df[\"instrument_type\"] == option_type) &\n",
    "                   (df[\"expiry\"] == expiry)]\n",
    "    \n",
    "    if symbol_df.empty:\n",
    "        return pd.DataFrame()  # no results\n",
    "\n",
    "    # if expiry is None:\n",
    "    #     # Pick nearest expiry\n",
    "    #     nearest_expiry = symbol_df[\"expiry\"].min()\n",
    "    #     filtered = symbol_df[symbol_df[\"expiry\"] == nearest_expiry]\n",
    "    # else:\n",
    "    #     filtered = symbol_df[symbol_df[\"expiry\"] == expiry]\n",
    "\n",
    "    return symbol_df.sort_values(by=\"strike\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0f41831-43f3-4d89-b73b-2f97f3c99b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 22:05:59,216 - INFO - selected_expiry : 2025-10-28\n",
      "2025-09-28 22:05:59,217 - INFO - Total symbols to process for CE is 218\n",
      "2025-09-28 22:05:59,479 - INFO -  ✅ Processing symbol number - 0\n",
      "2025-09-28 22:06:13,414 - INFO -  ✅ Processing symbol number - 50\n",
      "2025-09-28 22:06:24,912 - INFO -  ✅ Processing symbol number - 100\n",
      "2025-09-28 22:06:34,417 - ERROR - Skipping PEL: 'NSE:PEL'\n",
      "2025-09-28 22:06:36,763 - INFO -  ✅ Processing symbol number - 150\n",
      "2025-09-28 22:06:46,489 - INFO -  ✅ Processed all the symbols : 193\n"
     ]
    }
   ],
   "source": [
    "# Build a combined dataframe for all symbols\n",
    "all_options_df = pd.DataFrame()\n",
    "\n",
    "option_type=\"PE\"\n",
    "\n",
    "symbol_counter = 0\n",
    "expiry_date = get_expiry_date(instruments_df)\n",
    "if expiry_date is not None:    \n",
    "    logging.info(f\"Total symbols to process for {option_type} is {len(symbols)}\")\n",
    "    for sym in symbols:\n",
    "        try:       \n",
    "            last_traded_price = get_ltp(sym, exchange=\"NSE\")          \n",
    "            filtered_df = filter_option_strikes(instruments_df, sym, min_strike=last_traded_price, option_type=option_type, expiry=expiry_date)  # adjust min_strike & option_type\n",
    "            if not filtered_df.empty:\n",
    "                # print(f\"Processed {sym} - {last_traded_price}\")\n",
    "                all_options_df = pd.concat([all_options_df, filtered_df])                \n",
    "                if (symbol_counter % 50 == 0):\n",
    "                    logging.info(f\" ✅ Processing symbol number - {symbol_counter}\")\n",
    "                symbol_counter += 1                    \n",
    "        except Exception as e:\n",
    "            # print(f\"Skipping {sym}: {e}\")\n",
    "            logging.error(f\"Skipping {sym}: {e}\")\n",
    "else:\n",
    "     logging.error(\"Expiry is None... So cannot proceed further\")\n",
    "\n",
    "logging.info(f\" ✅ Processed all the symbols : {symbol_counter}\")\n",
    "# Reset index\n",
    "all_options_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "formatted = datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\n",
    "csv_filename = f\"zerodha_NFO_filtered_{option_type}_options_{formatted}.csv\"\n",
    "all_options_df.to_csv(csv_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ff68fa8-4a70-4866-95e1-0fc663873346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Function to fetch OHLC\n",
    "# ---------------------------\n",
    "\n",
    "def get_ohlc_last_20_days(instrument_token: int):\n",
    "    \"\"\"Fetch OHLC for last 20 days for a given instrument token.\"\"\"\n",
    "    to_date = datetime.today()\n",
    "    from_date = to_date - timedelta(days=20)\n",
    "    try:\n",
    "        data = kite.historical_data(\n",
    "            instrument_token,\n",
    "            from_date,\n",
    "            to_date,\n",
    "            interval=\"day\",\n",
    "            continuous=False,\n",
    "            oi=True\n",
    "        )\n",
    "        df = pd.DataFrame(data)\n",
    "        df[\"instrument_token\"] = instrument_token\n",
    "        \n",
    "        # Format the date column as YYYY-MM-DD\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching OHLC for {instrument_token} : {e}\")        \n",
    "        return pd.DataFrame()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81cb54f9-dff3-4145-9e5b-27a7f85cd337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 22:07:52,499 - INFO - ✅ Total tokens - 2792\n",
      "2025-09-28 22:07:52,833 - INFO - ✅ Processing token number - 0\n",
      "2025-09-28 22:08:15,348 - INFO - ✅ Processing token number - 100\n",
      "2025-09-28 22:08:36,153 - INFO - ✅ Processing token number - 200\n",
      "2025-09-28 22:08:56,188 - INFO - ✅ Processing token number - 300\n",
      "2025-09-28 22:09:17,480 - INFO - ✅ Processing token number - 400\n",
      "2025-09-28 22:09:38,374 - INFO - ✅ Processing token number - 500\n",
      "2025-09-28 22:09:58,604 - INFO - ✅ Processing token number - 600\n",
      "2025-09-28 22:10:18,985 - INFO - ✅ Processing token number - 700\n",
      "2025-09-28 22:10:39,766 - INFO - ✅ Processing token number - 800\n",
      "2025-09-28 22:11:00,659 - INFO - ✅ Processing token number - 900\n",
      "2025-09-28 22:11:21,586 - INFO - ✅ Processing token number - 1000\n",
      "2025-09-28 22:11:42,720 - INFO - ✅ Processing token number - 1100\n",
      "2025-09-28 22:12:04,519 - INFO - ✅ Processing token number - 1200\n",
      "2025-09-28 22:12:25,421 - INFO - ✅ Processing token number - 1300\n",
      "2025-09-28 22:12:47,495 - INFO - ✅ Processing token number - 1400\n",
      "2025-09-28 22:13:08,441 - INFO - ✅ Processing token number - 1500\n",
      "2025-09-28 22:13:29,224 - INFO - ✅ Processing token number - 1600\n",
      "2025-09-28 22:13:50,694 - INFO - ✅ Processing token number - 1700\n",
      "2025-09-28 22:14:12,692 - INFO - ✅ Processing token number - 1800\n",
      "2025-09-28 22:14:33,741 - INFO - ✅ Processing token number - 1900\n",
      "2025-09-28 22:14:55,300 - INFO - ✅ Processing token number - 2000\n",
      "2025-09-28 22:15:16,247 - INFO - ✅ Processing token number - 2100\n",
      "2025-09-28 22:15:36,885 - INFO - ✅ Processing token number - 2200\n",
      "2025-09-28 22:15:57,534 - INFO - ✅ Processing token number - 2300\n",
      "2025-09-28 22:16:18,899 - INFO - ✅ Processing token number - 2400\n",
      "2025-09-28 22:16:40,288 - INFO - ✅ Processing token number - 2500\n",
      "2025-09-28 22:17:01,696 - INFO - ✅ Processing token number - 2600\n",
      "2025-09-28 22:17:23,134 - INFO - ✅ Processing token number - 2700\n",
      "2025-09-28 22:17:43,219 - INFO - Total processed tokens: 2792\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Collect OHLC data for each instrument in filtered_df\n",
    "# ---------------------------\n",
    "ohlc_list = []\n",
    "\n",
    "logging.info(f\"✅ Total tokens - {len(all_options_df[\"instrument_token\"].unique())}\")\n",
    "counter = 0\n",
    "option_type = all_options_df[\"instrument_type\"][0]\n",
    "for token in all_options_df[\"instrument_token\"].unique():\n",
    "    ohlc_df = get_ohlc_last_20_days(token)\n",
    "\n",
    "    if ohlc_df is not None and not ohlc_df.empty:\n",
    "        ohlc_list.append(ohlc_df)        \n",
    "        if (counter % 100 == 0):\n",
    "            logging.info(f\"✅ Processing token number - {counter}\")\n",
    "        counter += 1\n",
    "    else:\n",
    "        # Append empty placeholder to keep token trace\n",
    "        placeholder = pd.DataFrame({\n",
    "            \"instrument_token\": [token],\n",
    "            \"date\": [pd.NaT],\n",
    "            \"open\": [None],\n",
    "            \"high\": [None],\n",
    "            \"low\": [None],\n",
    "            \"close\": [None],\n",
    "            \"volume\": [None]\n",
    "        })\n",
    "        ohlc_list.append(placeholder)\n",
    "        logging.warning(f\"⚠️ No OHLC data for token - {token}, added placeholder\")\n",
    "\n",
    "logging.info(f\"Total processed tokens: {counter}\")\n",
    "\n",
    "\n",
    "# Merge into one OHLC DataFrame\n",
    "ohlc_all_df = pd.concat(ohlc_list, ignore_index=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Join with filtered_df to add symbol, expiry, strike, option_type\n",
    "# ---------------------------\n",
    "# Ensure filtered_df has these columns:\n",
    "# tradingsymbol, expiry, strike, instrument_type, instrument_token\n",
    "daily_ohlc_df = ohlc_all_df.merge(all_options_df[[\"instrument_token\", \"expiry\", \"name\", \"strike\", \"instrument_type\"]],\n",
    "    on=\"instrument_token\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Rename for clarity\n",
    "daily_ohlc_df.rename(columns={\"instrument_type\": \"option_type\"}, inplace=True)\n",
    "\n",
    "daily_ohlc_df.head(5)\n",
    "\n",
    "formatted = datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\n",
    "csv_filename = f\"zerodha_NFO_filtered_{option_type}_daily_OHLC_{formatted}.csv\"\n",
    "daily_ohlc_df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e9a49aa-7813-4f18-8721-2f6ac2f950fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 22:19:12,046 - INFO - Today is : 6\n",
      "2025-09-28 22:19:16,279 - INFO - Before holiday check --> 2025-09-15, 2025-09-19, 2025-09-22, 2025-09-26\n",
      "2025-09-28 22:19:17,326 - INFO - 2025-09-15 is NOT a holiday.\n",
      "2025-09-28 22:19:18,395 - INFO - 2025-09-22 is NOT a holiday.\n",
      "2025-09-28 22:19:18,935 - INFO - 2025-09-19 is NOT a holiday.\n",
      "2025-09-28 22:19:19,459 - INFO - 2025-09-26 is NOT a holiday.\n",
      "2025-09-28 22:19:19,462 - INFO - After holiday check --> 2025-09-15, 2025-09-19, 2025-09-22, 2025-09-26\n"
     ]
    }
   ],
   "source": [
    "first_week_open_date, first_week_close_date, last_week_open_date, last_week_close_date = get_working_days()\n",
    "\n",
    "first_week_open_date = first_week_open_date.strftime(\"%Y-%m-%d\")\n",
    "first_week_close_date = first_week_close_date.strftime(\"%Y-%m-%d\")\n",
    "last_week_open_date = last_week_open_date.strftime(\"%Y-%m-%d\")\n",
    "last_week_close_date = last_week_close_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# print(daily_ohlc_df['date'][6])\n",
    "# print(first_week_open_date)\n",
    "\n",
    "######## Load weekly OHCL for testing ONLY ######\n",
    "# import pandas as pd\n",
    "# file_name = \"zerodha_NFO_filtered_daily_OHLC_29-Aug-2025 00-00-57.csv\"\n",
    "# daily_ohlc_df = pd.read_csv(file_name)\n",
    "#############\n",
    "\n",
    "weekly_ohlc_df = daily_ohlc_df[daily_ohlc_df['date'].isin([first_week_open_date, \n",
    "                                                                           first_week_close_date, last_week_open_date, last_week_close_date])]\n",
    "formatted = datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\n",
    "csv_filename = f\"zerodha_NFO_filtered_{option_type}_weekly_OHLC_{formatted}.csv\"\n",
    "weekly_ohlc_df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04f021c2-3339-4180-9ac2-bebd32afb9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_green_bullish_candles(final_df):\n",
    "    bullish_message = None\n",
    "    if len(final_df) == 4:\n",
    "        openFlag = False\n",
    "        closeFlag = False\n",
    "\n",
    "        row = final_df.iloc[0]\n",
    "        if (row['open'] == '0.00') and (row['high'] == '0.00') and (row['low'] == '0.00'):\n",
    "            final_df.at[final_df.index[0], 'open'] = row['close']\n",
    "\n",
    "        row = final_df.iloc[1]\n",
    "        if (row['open'] == '0.00') and (row['high'] == '0.00') and (row['low'] == '0.00'):\n",
    "            final_df.at[final_df.index[1], 'open'] = row['close']\n",
    "\n",
    "        row = final_df.iloc[2]\n",
    "        if (row['open'] == '0.00') and (row['high'] == '0.00') and (row['low'] == '0.00'):\n",
    "            final_df.at[final_df.index[2], 'open'] = row['close']\n",
    "\n",
    "        row = final_df.iloc[3]\n",
    "        if (row['open'] == '0.00') and (row['high'] == '0.00') and (row['low'] == '0.00'):\n",
    "            final_df.at[final_df.index[3], 'open'] = row['close']\n",
    "\n",
    "        # print(\n",
    "        #     f\"first_week_open_date - {final_df.iloc[3]['open']}, first_week_close_date - {final_df.iloc[2]['close']}\")\n",
    "        # print(\n",
    "        #     f\"last_week_open_date - {final_df.iloc[1]['open']}, last_week_close_date - {final_df.iloc[0]['close']}\")\n",
    "\n",
    "        # Validate if each week is GREEN candle\n",
    "        if ((float(final_df.iloc[3]['close']) > float(final_df.iloc[2]['open'])) and\n",
    "                (float(final_df.iloc[1]['close']) > float(final_df.iloc[0]['open']))):\n",
    "\n",
    "            # Check if the last week open day price is less than or equal to the first week open day price\n",
    "            if final_df.iloc[2]['open'] <= final_df.iloc[0]['open']:\n",
    "                # print(\"last_week_open_date open is lower than the first_week_open_date.\")\n",
    "                openFlag = True\n",
    "         \n",
    "            # Check if the last week close day price is greater than or equal to the first week close day price\n",
    "            if final_df.iloc[3]['close'] >= final_df.iloc[1]['close']:\n",
    "                # print(\"last_week_close_date close is higher than first_week_close_date.\")\n",
    "                closeFlag = True\n",
    "           \n",
    "            # print(openFlag, closeFlag)\n",
    "            if (openFlag & closeFlag):\n",
    "                # print(final_df)\n",
    "                bullish_message = f\"***** GREEN bullish ****** {final_df.iloc[0]['name']}, {final_df.iloc[0]['strike']}, {final_df.iloc[0]['expiry']} ***** \"\n",
    "                # write_to_log(bullish_message)\n",
    "        #     else:\n",
    "        #         bullish_message = f\"NOT bullish, {final_df.iloc[0]['strike']}, {final_df.iloc[0]['EXPIRY_DT']}\"\n",
    "        # else:\n",
    "        #     bullish_message = f\"NOT bullish, {final_df.iloc[0]['strike']}, {final_df.iloc[0]['EXPIRY_DT']}\"\n",
    "    # else:\n",
    "    #     if not final_df.empty:\n",
    "    #         bullish_message = f\"Insufficient data for {final_df.iloc[0]['strike']}, {final_df.iloc[0]['EXPIRY_DT']}\"\n",
    "    #     else:\n",
    "    #         bullish_message = f\"Insufficient data\"\n",
    "\n",
    "    # print(bullish_message)\n",
    "    return bullish_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91bed2d8-006c-41af-99ee-d89d3ccec675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 22:21:13,414 - INFO - Program completed\n"
     ]
    }
   ],
   "source": [
    "# ####### Load weekly OHCL for testing ONLY ######\n",
    "# import pandas as pd\n",
    "# file_name = \"zerodha_NFO_filtered_CE_weekly_OHLC_06-Sep-2025 22-03-09.csv\"\n",
    "# weekly_ohlc_df = pd.read_csv(file_name)\n",
    "# ############\n",
    "\n",
    "unique_symbols = weekly_ohlc_df['name'].unique()\n",
    "# unique_strike_prices  = weekly_ohlc_df['strike'].unique()\n",
    "# unique_strike_prices = ['290.00']\n",
    "\n",
    "message = \"Not Green bullish candle found\"\n",
    "try:\n",
    "    with open(\"output.txt\", \"w\") as file_object:\n",
    "        for symbol in unique_symbols:\n",
    "            symbol_df = weekly_ohlc_df[weekly_ohlc_df['name'] == symbol]\n",
    "            unique_strike_prices  = symbol_df['strike'].unique()\n",
    "            for strike_price in unique_strike_prices:      \n",
    "                # logging.info(f\" Processing {weekly_ohlc_df['name']} for {weekly_ohlc_df['strike']}\")\n",
    "                final_df = symbol_df[symbol_df['strike'] == strike_price]\n",
    "                # print(final_df)\n",
    "                # logging.info(f\" df size - {len(final_df)}\")\n",
    "                # message.append(f\"Line {strike_price}\")\n",
    "                message = find_green_bullish_candles(final_df)\n",
    "               \n",
    "                if message is not None:\n",
    "                    # print(message)\n",
    "                    file_object.write(f\"{message}\\n\")                  \n",
    "                \n",
    "except IOError as e:\n",
    " logging.error(f\"An I/O error occurred while writing output : {e}\")\n",
    "except Exception as e:\n",
    " logging.error(f\"Exception occurred while writing output : {e}\")\n",
    "\n",
    "finally:\n",
    "    file_object.close() \n",
    "    logging.info(f\"Program completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dba51d-9917-432b-bac4-91d4c2e77611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
